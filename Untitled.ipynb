{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary:     A collections of functions to generate features.\n",
    "Description:\n",
    "Author:      Kunyu He, CAPP'20\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------#\n",
    "INPUT_DIR = \"./data/\"\n",
    "OUTPUT_DIR = \"./processed_data/\"\n",
    "LOG_DIR = \"./logs/featureEngineering/\"\n",
    "\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "\n",
    "SCALERS = [StandardScaler, MinMaxScaler]\n",
    "\n",
    "# logging\n",
    "logger= logging.getLogger('featureEngineering')\n",
    "logger.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "logger.addHandler(ch)\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------#\n",
    "def read_data(file_name, drop_na=False):\n",
    "    \"\"\"\n",
    "    Read credit data in the .csv file and data types from the .json file.\n",
    "\n",
    "    Inputs:\n",
    "        - data_file (string): name of the data file.\n",
    "        - drop_na (bool): whether to drop rows with any missing values\n",
    "\n",
    "    Returns:\n",
    "        (DataFrame) clean data set with correct data types\n",
    "\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(INPUT_DIR + file_name)\n",
    "\n",
    "    if drop_na:\n",
    "        data.dropna(axis=0, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def ask():\n",
    "    \"\"\"\n",
    "    Ask user for choice of an imputer and a scaler.\n",
    "\n",
    "    \"\"\"\n",
    "    scaler_index = int(input((\"Up till now we support:\\n\"\n",
    "                              \"\\t1. StandardScaler\\n\"\n",
    "                              \"\\t2. MinMaxScaler\\n\"\n",
    "                              \"Please input a scaler index (1 or 2):\\n\")))\n",
    "\n",
    "    return scaler_index\n",
    "\n",
    "\n",
    "class FeaturePipeLine:\n",
    "    \"\"\"\n",
    "    Preprocess pipeline for a data set from CSV file. Modify the class\n",
    "    variables to fill in missing values, combine multinomial variables to ones\n",
    "    with less levels and binaries, and apply one-hot-encoding. Then split data\n",
    "    into features and traget, drop rows with missing labels and some columns.\n",
    "    At last, apply scaling.\n",
    "\n",
    "    \"\"\"\n",
    "    TO_DESCRETIZE = {'Age': 5}\n",
    "    RIGHT_INCLUSIVE = {'Age': True}\n",
    "\n",
    "    TO_FILL_NA = {'Cabin': \"None\",\n",
    "                  'Embarked': \"Unknown\"}\n",
    "\n",
    "    TO_COMBINE = {}\n",
    "    TO_BINARIES = {'Sex': 'auto',\n",
    "                   'Cabin': 'auto'}\n",
    "    TO_ONE_HOT = {'Pclass', 'Embarked', 'Age'}\n",
    "\n",
    "    TARGET = 'Survived'\n",
    "    TO_DROP = ['PassengerId', 'Ticket', 'Name']\n",
    "\n",
    "    SCALERS = [StandardScaler, MinMaxScaler]\n",
    "    SCALER_NAMES = [\"Standard Scaler\", \"MinMax Scaler\"]\n",
    "\n",
    "    def __init__(self, file_name, ask_user=True, verbose=True, drop_na=False):\n",
    "        \"\"\"\n",
    "        Construct a preprocessing pipeline given name of the data file.\n",
    "\n",
    "        Inputs:\n",
    "            - file_name (string): name of the data file\n",
    "            - verbose (bool): whether to make extended printing in\n",
    "                preprocessing\n",
    "            - drop_na (bool): whether to drop rows with missing values\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info((\"**-----------------------------------------------**\\n\"))\n",
    "        logger.info(\"Creating the preprocessing pipeline for '{}'.\".format(\\\n",
    "            file_name))\n",
    "        self.data = read_data(file_name, drop_na)\n",
    "        self.verbose = verbose\n",
    "        logger.info(\"Finished reading cleaned data.\")\n",
    "\n",
    "        if ask_user:\n",
    "            self.scaler_index = ask()\n",
    "        else:\n",
    "            self.scaler_index = 1\n",
    "        logger.info(\"Pipeline using scaler {}\".\\\n",
    "                    format(self.SCALER_NAMES[self.scaler_index - 1]))\n",
    "\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def discretize(self):\n",
    "        \"\"\"\n",
    "        Discretizes continuous variables into multinomials.\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info((\"\\n\\n**-------------------------------------------**\\n\"))\n",
    "        logger.info(\"Start to discretizes continuous variables:\")\n",
    "\n",
    "        for var, n in self.TO_DESCRETIZE.items():\n",
    "            self.data[var] = pd.cut(self.data[var], n,\n",
    "                                    right=self.RIGHT_INCLUSIVE[var]).cat.codes\n",
    "\n",
    "            if self.verbose:\n",
    "                if not self.data[var].isnull().sum():\n",
    "                    logger.info((\"\\tThere are missing values in '{}', \"\n",
    "                        \"discretized it into {} bins, where '-1' indicates \"\n",
    "                        \"that the value is missing.\".format(var, n + 1)))\n",
    "                else:\n",
    "                    logger.info(\"\\tDiscretized '{}' into {} bins.\".\\\n",
    "                                format(var, n))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fill_na(self):\n",
    "        \"\"\"\n",
    "        Fill in missing data with desired entry.\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info((\"\\n\\n**-------------------------------------------**\\n\"))\n",
    "        logger.info(\"Start to fill in missing values:\")\n",
    "\n",
    "        for var, fill in self.TO_FILL_NA.items():\n",
    "            self.data[var].fillna(value=fill, inplace=True)\n",
    "\n",
    "            if self.verbose:\n",
    "                logger.info(\"\\tFilled missing values in '{}' with '{}'.\".\\\n",
    "                      format(var, fill))\n",
    "\n",
    "            if fill == \"None\":\n",
    "                to_combine = [col for col in list(self.data[var].unique())\n",
    "                              if col != \"None\"]\n",
    "                self.TO_COMBINE[var] = {\"Yes\": to_combine}\n",
    "                logger.info(\"\\t\\t'{}' added to 'TO_COMBINE'\".format(var))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def to_combine(self):\n",
    "        \"\"\"\n",
    "        Combine some unecessary levels of multinomials.\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info((\"\\n\\n**-------------------------------------------**\\n\"))\n",
    "        logger.info(\"Start to combine unnecessary levels of multinomials.\")\n",
    "\n",
    "        for var, dict_combine in self.TO_COMBINE.items():\n",
    "            for combined, lst_combine in dict_combine.items():\n",
    "                self.data.loc[self.data[var].isin(lst_combine), var] = combined\n",
    "\n",
    "            if self.verbose:\n",
    "                logger.info(\"\\tCombinations of levels on '{}'.\".format(var))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def to_binary(self):\n",
    "        \"\"\"\n",
    "        Trasform variables to binaries.\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info((\"\\n\\n**-------------------------------------------**\\n\"))\n",
    "        logger.info((\"Start to transform the following variables: {} to \"\n",
    "                     \"Binaries.\").format(list(self.TO_BINARIES.keys())))\n",
    "\n",
    "        for var, cats in self.TO_BINARIES.items():\n",
    "            enc = OrdinalEncoder(categories=cats)\n",
    "            self.data[var] = enc.fit_transform(np.array(self.data[var]).\\\n",
    "                                               reshape(-1, 1))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def one_hot(self):\n",
    "        \"\"\"\n",
    "        Ccreates binary/dummy variables from multinomials, drops the original\n",
    "        and inserts the dummies back.\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info((\"\\n\\n**-------------------------------------------**\\n\"))\n",
    "        logger.info((\"Start to apply one-hot-encoding to the following \"\n",
    "                     \"categorical variables: {}\\n\").format(self.TO_ONE_HOT))\n",
    "\n",
    "        for var in self.TO_ONE_HOT:\n",
    "            dummies = pd.get_dummies(self.data[var], prefix=var)\n",
    "            self.data.drop(var, axis=1, inplace=True)\n",
    "            self.data = pd.concat([self.data, dummies], axis=1)\n",
    "\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "**-----------------------------------------------**\n",
      "\n",
      "Creating the preprocessing pipeline for 'train.csv'.\n",
      "Finished reading cleaned data.\n",
      "Pipeline using scaler Standard Scaler\n",
      "\n",
      "\n",
      "**-------------------------------------------**\n",
      "\n",
      "Start to discretizes continuous variables:\n",
      "\tThere are missing values in 'Age', discretized it into 6 bins, where '-1' indicates that the value is missing.\n",
      "\n",
      "\n",
      "**-------------------------------------------**\n",
      "\n",
      "Start to fill in missing values:\n",
      "\tFilled missing values in 'Cabin' with 'None'.\n",
      "\t\t'Cabin' added to 'TO_COMBINE'\n",
      "\tFilled missing values in 'Embarked' with 'Unknown'.\n",
      "\n",
      "\n",
      "**-------------------------------------------**\n",
      "\n",
      "Start to combine unnecessary levels of multinomials.\n",
      "\tCombinations of levels on 'Cabin'.\n",
      "\n",
      "\n",
      "**-------------------------------------------**\n",
      "\n",
      "Start to transform the following variables: ['Sex', 'Cabin'] to Binaries.\n",
      "\n",
      "\n",
      "**-------------------------------------------**\n",
      "\n",
      "Start to apply one-hot-encoding to the following categorical variables: {'Embarked', 'Pclass', 'Age'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.FeaturePipeLine at 0x22a9f99dc50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = FeaturePipeLine(TRAIN_FILE, ask_user=False)\n",
    "pipe.discretize().fill_na().to_combine().to_binary().one_hot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked_Unknown</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Age_-1</th>\n",
       "      <th>Age_0</th>\n",
       "      <th>Age_1</th>\n",
       "      <th>Age_2</th>\n",
       "      <th>Age_3</th>\n",
       "      <th>Age_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "   Sex  SibSp  Parch            Ticket     Fare  Cabin  Embarked_C  ...  \\\n",
       "0  1.0      1      0         A/5 21171   7.2500    0.0           0  ...   \n",
       "1  0.0      1      0          PC 17599  71.2833    1.0           1  ...   \n",
       "2  0.0      0      0  STON/O2. 3101282   7.9250    0.0           0  ...   \n",
       "3  0.0      1      0            113803  53.1000    1.0           0  ...   \n",
       "4  1.0      0      0            373450   8.0500    0.0           0  ...   \n",
       "\n",
       "   Embarked_Unknown  Pclass_1  Pclass_2  Pclass_3  Age_-1  Age_0  Age_1  \\\n",
       "0                 0         0         0         1       0      0      1   \n",
       "1                 0         1         0         0       0      0      0   \n",
       "2                 0         0         0         1       0      0      1   \n",
       "3                 0         1         0         0       0      0      0   \n",
       "4                 0         0         0         1       0      0      0   \n",
       "\n",
       "   Age_2  Age_3  Age_4  \n",
       "0      0      0      0  \n",
       "1      1      0      0  \n",
       "2      0      0      0  \n",
       "3      1      0      0  \n",
       "4      1      0      0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PassengerId,Survived,Name,Sex,SibSp,Parch,Ticket,Fare,Cabin,Embarked_C,Embarked_Q,Embarked_S,Embarked_Unknown,Pclass_1,Pclass_2,Pclass_3,Age_-1,Age_0,Age_1,Age_2,Age_3,Age_4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(pipe.data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId         0\n",
       "Survived            0\n",
       "Name                0\n",
       "Sex                 0\n",
       "SibSp               0\n",
       "Parch               0\n",
       "Ticket              0\n",
       "Fare                0\n",
       "Cabin               0\n",
       "Embarked_C          0\n",
       "Embarked_Q          0\n",
       "Embarked_S          0\n",
       "Embarked_Unknown    0\n",
       "Pclass_1            0\n",
       "Pclass_2            0\n",
       "Pclass_3            0\n",
       "Age_-1              0\n",
       "Age_0               0\n",
       "Age_1               0\n",
       "Age_2               0\n",
       "Age_3               0\n",
       "Age_4               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
